# Python Tools

This directory contains command-line tools for managing property data in the House Tracker system.

## Tools Overview

### 1. Property Query Tool (`property_query_tool.py`)

A command-line tool for querying properties from DynamoDB using the DynamoDBPropertyService. This tool allows you to retrieve property information by either property ID or address.

#### Features
- Query properties by ID or address
- Support for custom DynamoDB table and region configuration
- Multiple output formats (summary and JSON)
- Verbose logging option
- Error handling and validation

#### Usage

```bash
# Query by property ID
python property_query_tool.py --id "e329420e-4dc6-4d88-bfe7-222a268c82b9"

# Query by address
python property_query_tool.py --address "7503 152nd Ave NE, Redmond, WA 98052"

# Use custom table and region
python property_query_tool.py --id "some-id" --table "my-properties" --region "us-east-1"

# Output as JSON format
python property_query_tool.py --id "some-id" --output-format json

# Enable verbose logging
python property_query_tool.py --id "some-id" --verbose
```

#### Command Line Arguments

| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `--id` | string | - | Property ID to query (mutually exclusive with --address) |
| `--address` | string | - | Property address to query (mutually exclusive with --id) |
| `--table` | string | "properties" | DynamoDB table name |
| `--region` | string | "us-west-2" | AWS region |
| `--output-format` | choice | "summary" | Output format: "summary" or "json" |
| `-v, --verbose` | flag | False | Enable verbose logging |

#### Output Formats

**Summary Format (default):**
```
Property Details:
================
[Property object string representation]
```

**JSON Format:**
```json
{
  "id": "property-id",
  "address": {
    "street_name": "123 Main St",
    "unit": null,
    "city": "Seattle",
    "state": "WA",
    "zip_code": "98101",
    "address_hash": "hash-value"
  },
  "property_type": "SINGLE_FAMILY",
  "status": "FOR_SALE",
  "price": 750000.0,
  "area": {
    "value": 2000.0,
    "unit": "SQ_FT"
  },
  "number_of_bedrooms": 3.0,
  "number_of_bathrooms": 2.0,
  "year_built": 2010,
  "last_updated": "2024-01-01T00:00:00",
  "data_sources": [...],
  "history": [...]
}
```

### 2. Property Store Tool (`property_store_tool.py`)

A tool for storing property data from JSONL files into DynamoDB. This tool processes property data files generated by the Redfin crawler and stores them in the database.

#### Features
- Batch processing of property data files
- Configurable delay intervals to prevent rate limiting
- Error logging for failed property parsing
- Progress tracking and logging
- Support for processing file ranges

#### Usage

The tool is primarily designed to be run as a script with hardcoded configuration in the `main()` function. To use it:

1. Edit the configuration variables in the `main()` function:
   ```python
   start_file = "redfin_properties_20250907_110044.jsonl"
   end_file = "redfin_properties_20250916_190913.jsonl"
   delay_seconds = 2
   delay_interval = 200
   ```

2. Run the tool:
   ```bash
   python property_store_tool.py
   ```

#### Configuration

The tool processes files from the `../crawler/redfin_output/` directory and stores them in DynamoDB with the following default settings:
- **Table**: "properties"
- **Region**: "us-west-2"
- **Delay**: 2 seconds every 200 properties
- **File delay**: 60 seconds between files

#### File Processing

The tool will:
1. Find all files between `start_file` and `end_file` (inclusive) in alphabetical order
2. Process each file sequentially
3. For each property in the file:
   - Parse the property data
   - Store/update in DynamoDB
   - Log progress and any errors
   - Apply delays as configured
4. Generate error logs in `logs/data_reader_errors_YYYYMMDD_HHMMSS.log`

#### Error Handling

- Property parsing errors are logged to a dedicated error file
- Service errors are logged to the main log file
- The tool continues processing even if individual properties fail

## Prerequisites

Before using these tools, ensure you have:

1. **Python Environment**: Use pipenv to manage dependencies
   ```bash
   cd python
   pipenv shell
   ```

2. **AWS Credentials**: Configure AWS credentials for DynamoDB access
   ```bash
   aws configure sso
   ```

3. **DynamoDB Table**: Ensure the "properties" table exists in your AWS region

## Dependencies

The tools depend on the following modules:
- `shared.iproperty` - Property data models
- `shared.iproperty_address` - Address handling
- `shared.logger_factory` - Logging configuration
- `data_service.dynamodb_property_service` - DynamoDB operations
- `data_service.redfin_data_reader` - File data reading (store tool only)

## Logging

Both tools use the shared logger factory for consistent logging:
- **Query Tool**: Console logging only (configurable)
- **Store Tool**: File logging to `logs/` directory with timestamps

## Error Codes

- **Exit Code 1**: Property not found (query tool)
- **Exit Code 1**: Invalid address format (query tool)
- **Exit Code 1**: Unexpected errors or user interruption

## Examples

### Query Examples

```bash
# Find a property by ID
python property_query_tool.py --id "abc123" --verbose

# Find a property by address with JSON output
python property_query_tool.py --address "123 Main St, Seattle, WA 98101" --output-format json

# Use different AWS region
python property_query_tool.py --id "abc123" --region "us-east-1" --table "dev-properties"
```

### Store Tool Configuration

To process a specific range of files, modify the `main()` function:

```python
def main() -> None:
    # ... logging setup ...
    
    # Configuration
    start_file = "redfin_properties_20250901_000000.jsonl"
    end_file = "redfin_properties_20250915_235959.jsonl"
    
    delay_seconds = 1      # Delay between batches
    delay_interval = 100   # Process 100 properties before delay
    
    store_properties_to_db(
        property_data_dir,
        start_file,
        end_file,
        delay_seconds,
        delay_interval,
    )
```

## Troubleshooting

### Common Issues

1. **AWS Credentials**: Ensure AWS credentials are properly configured
2. **Table Permissions**: Verify DynamoDB table exists and you have write permissions
3. **File Paths**: Check that property data files exist in the expected directory
4. **Memory Usage**: For large files, consider processing smaller batches

### Log Files

- **Query Tool**: Console output only
- **Store Tool**: 
  - Main log: `logs/property_store_tool_YYYYMMDD_HHMMSS.log`
  - Error log: `logs/data_reader_errors_YYYYMMDD_HHMMSS.log`

## Development

To extend these tools:

1. **Add new query methods**: Extend the query tool with additional search criteria
2. **Support new data sources**: Modify the store tool to handle different file formats
3. **Add validation**: Implement additional data validation before storage
4. **Performance optimization**: Add parallel processing for large datasets
